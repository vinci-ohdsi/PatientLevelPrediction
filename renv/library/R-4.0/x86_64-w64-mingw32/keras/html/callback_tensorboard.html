<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: TensorBoard basic visualizations</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for callback_tensorboard {keras}"><tr><td>callback_tensorboard {keras}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>TensorBoard basic visualizations</h2>

<h3>Description</h3>

<p>This callback writes a log for TensorBoard, which allows you to visualize
dynamic graphs of your training and test metrics, as well as activation
histograms for the different layers in your model.
</p>


<h3>Usage</h3>

<pre>
callback_tensorboard(
  log_dir = NULL,
  histogram_freq = 0,
  batch_size = NULL,
  write_graph = TRUE,
  write_grads = FALSE,
  write_images = FALSE,
  embeddings_freq = 0,
  embeddings_layer_names = NULL,
  embeddings_metadata = NULL,
  embeddings_data = NULL,
  update_freq = "epoch",
  profile_batch = 0
)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>log_dir</code></td>
<td>
<p>The path of the directory where to save the log files to be
parsed by Tensorboard. The default is <code>NULL</code>, which will use the active
run directory (if available) and otherwise will use &quot;logs&quot;.</p>
</td></tr>
<tr valign="top"><td><code>histogram_freq</code></td>
<td>
<p>frequency (in epochs) at which to compute activation
histograms for the layers of the model. If set to 0, histograms won't be
computed.</p>
</td></tr>
<tr valign="top"><td><code>batch_size</code></td>
<td>
<p>size of batch of inputs to feed to the network
for histograms computation. No longer needed, ignored since TF 1.14.</p>
</td></tr>
<tr valign="top"><td><code>write_graph</code></td>
<td>
<p>whether to visualize the graph in Tensorboard. The log
file can become quite large when write_graph is set to <code>TRUE</code></p>
</td></tr>
<tr valign="top"><td><code>write_grads</code></td>
<td>
<p>whether to visualize gradient histograms in TensorBoard.
<code>histogram_freq</code> must be greater than 0.</p>
</td></tr>
<tr valign="top"><td><code>write_images</code></td>
<td>
<p>whether to write model weights to visualize as image in
Tensorboard.</p>
</td></tr>
<tr valign="top"><td><code>embeddings_freq</code></td>
<td>
<p>frequency (in epochs) at which selected embedding
layers will be saved.</p>
</td></tr>
<tr valign="top"><td><code>embeddings_layer_names</code></td>
<td>
<p>a list of names of layers to keep eye on. If
<code>NULL</code> or empty list all the embedding layers will be watched.</p>
</td></tr>
<tr valign="top"><td><code>embeddings_metadata</code></td>
<td>
<p>a named list which maps layer name to a file name in
which metadata for this embedding layer is saved. See the
<a href="https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin#saving_data_for_tensorboard">details</a>
about the metadata file format. In case if the same metadata file is used
for all embedding layers, string can be passed.</p>
</td></tr>
<tr valign="top"><td><code>embeddings_data</code></td>
<td>
<p>Data to be embedded at layers specified in
<code>embeddings_layer_names</code>. Array (if the model has a single input) or list
of arrays (if the model has multiple inputs). Learn <a href="https://www.tensorflow.org/text/guide/word_embeddings">more about embeddings</a></p>
</td></tr>
<tr valign="top"><td><code>update_freq</code></td>
<td>
<p><code>'batch'</code> or <code>'epoch'</code> or integer. When using <code>'batch'</code>, writes
the losses and metrics to TensorBoard after each batch. The same
applies for <code>'epoch'</code>. If using an integer, let's say <code>10000</code>,
the callback will write the metrics and losses to TensorBoard every
10000 samples. Note that writing too frequently to TensorBoard
can slow down your training.</p>
</td></tr>
<tr valign="top"><td><code>profile_batch</code></td>
<td>
<p>Profile the batch to sample compute characteristics. By
default, it will disbale profiling. Set profile_batch=2 profile the second
batch. Must run in TensorFlow eager mode. (TF &gt;= 1.14)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TensorBoard is a visualization tool provided with TensorFlow.
</p>
<p>You can find more information about TensorBoard
<a href="https://www.tensorflow.org/tensorboard/get_started">here</a>.
</p>
<p>When using a backend other than TensorFlow, TensorBoard will still work
(if you have TensorFlow installed), but the only feature available will
be the display of the losses and metrics plots.
</p>


<h3>See Also</h3>

<p>Other callbacks: 
<code><a href="callback_csv_logger.html">callback_csv_logger</a>()</code>,
<code><a href="callback_early_stopping.html">callback_early_stopping</a>()</code>,
<code><a href="callback_lambda.html">callback_lambda</a>()</code>,
<code><a href="callback_learning_rate_scheduler.html">callback_learning_rate_scheduler</a>()</code>,
<code><a href="callback_model_checkpoint.html">callback_model_checkpoint</a>()</code>,
<code><a href="callback_progbar_logger.html">callback_progbar_logger</a>()</code>,
<code><a href="callback_reduce_lr_on_plateau.html">callback_reduce_lr_on_plateau</a>()</code>,
<code><a href="callback_remote_monitor.html">callback_remote_monitor</a>()</code>,
<code><a href="callback_terminate_on_naan.html">callback_terminate_on_naan</a>()</code>
</p>

<hr /><div style="text-align: center;">[Package <em>keras</em> version 2.6.1 <a href="00Index.html">Index</a>]</div>
</body></html>
