<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Fast GRU implementation backed by CuDNN.</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for layer_cudnn_gru {keras}"><tr><td>layer_cudnn_gru {keras}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Fast GRU implementation backed by <a href="https://developer.nvidia.com/cudnn">CuDNN</a>.</h2>

<h3>Description</h3>

<p>Can only be run on GPU, with the TensorFlow backend.
</p>


<h3>Usage</h3>

<pre>
layer_cudnn_gru(
  object,
  units,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  return_sequences = FALSE,
  return_state = FALSE,
  stateful = FALSE,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>object</code></td>
<td>
<p>What to call the new <code>Layer</code> instance with. Typically a keras
<code>Model</code>, another <code>Layer</code>, or a <code>tf.Tensor</code>/<code>KerasTensor</code>. If <code>object</code> is
missing, the <code>Layer</code> instance is returned, otherwise, <code>layer(object)</code> is
returned.</p>
</td></tr>
<tr valign="top"><td><code>units</code></td>
<td>
<p>Positive integer, dimensionality of the output space.</p>
</td></tr>
<tr valign="top"><td><code>kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix, used
for the linear transformation of the inputs.</p>
</td></tr>
<tr valign="top"><td><code>recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code> weights
matrix, used for the linear transformation of the recurrent state.</p>
</td></tr>
<tr valign="top"><td><code>bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr valign="top"><td><code>kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr valign="top"><td><code>recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr valign="top"><td><code>bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr valign="top"><td><code>activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr valign="top"><td><code>kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix.</p>
</td></tr>
<tr valign="top"><td><code>recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr valign="top"><td><code>bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr valign="top"><td><code>return_sequences</code></td>
<td>
<p>Boolean. Whether to return the last output in the
output sequence, or the full sequence.</p>
</td></tr>
<tr valign="top"><td><code>return_state</code></td>
<td>
<p>Boolean (default FALSE). Whether to return the last state
in addition to the output.</p>
</td></tr>
<tr valign="top"><td><code>stateful</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the last state for each
sample at index i in a batch will be used as initial state for the sample
of index i in the following batch.</p>
</td></tr>
<tr valign="top"><td><code>input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr valign="top"><td><code>batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr valign="top"><td><code>batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr valign="top"><td><code>dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr valign="top"><td><code>name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr valign="top"><td><code>trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr valign="top"><td><code>weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1409.1259">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</a>
</p>
</li>
<li> <p><a href="https://arxiv.org/abs/1412.3555v1">Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</a>
</p>
</li>
<li> <p><a href="https://arxiv.org/abs/1512.05287">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other recurrent layers: 
<code><a href="layer_cudnn_lstm.html">layer_cudnn_lstm</a>()</code>,
<code><a href="layer_gru.html">layer_gru</a>()</code>,
<code><a href="layer_lstm.html">layer_lstm</a>()</code>,
<code><a href="layer_simple_rnn.html">layer_simple_rnn</a>()</code>
</p>

<hr /><div style="text-align: center;">[Package <em>keras</em> version 2.6.1 <a href="00Index.html">Index</a>]</div>
</body></html>
